{"backend_state":"init","kernel":"python3-ubuntu","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"trust":false,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"c3e063","input":"","pos":53,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"ec9190","input":"","pos":52,"type":"cell"}
{"cell_type":"code","exec_count":1,"id":"15ec25","input":"import numpy as np\nimport matplotlib.pyplot as plt","pos":1,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"7e1c0b","input":"from sklearn.linear_model import Perceptron\n# define model\nclassifier = Perceptron()\n# fit model\nclassifier.fit(X, y)","output":{"0":{"data":{"text/plain":"Perceptron()"},"exec_count":10,"output_type":"execute_result"}},"pos":10,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"0bf2dd","input":"# make predictions\nexpected = y  # true value \npredicted = classifier.predict(X) ","pos":11,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"dc92ad","input":"# evaulate your model\nfrom sklearn import metrics\nprint(metrics.classification_report(expected, predicted))\nprint(metrics.confusion_matrix(expected, predicted))","output":{"0":{"name":"stdout","output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       500\n           1       1.00      1.00      1.00       500\n\n    accuracy                           1.00      1000\n   macro avg       1.00      1.00      1.00      1000\nweighted avg       1.00      1.00      1.00      1000\n\n[[500   0]\n [  0 500]]\n"}},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"9c6e23","input":"# Plot non-normalized confusion matrix\nfrom sklearn.metrics import plot_confusion_matrix\ntitles_options = [(\"Confusion matrix\", None)]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(classifier, X, y,\n                                 display_labels=y,\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title, FontSize = 20)\nplt.show()","output":{"0":{"data":{"image/png":"4b68ac15dac7f271d4357bb358a230d281921bec","text/plain":"<Figure size 864x504 with 2 Axes>"},"exec_count":13,"metadata":{"image/png":{"height":446,"width":500},"needs_background":"light"},"output_type":"execute_result"}},"pos":14,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"33ee68","input":"# Plot the decision boundary. For that, we will assign a color to each\n# point in the mesh [x_min, x_max]x[y_min, y_max].\nx_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\ny_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\nh = .02  # step size in the mesh\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\nZ = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n\n# Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure(1, figsize=(7, 5))\nplt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n\n# Plot also the training points\nplt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.xticks(())\nplt.yticks(())\n\nplt.show()","output":{"0":{"data":{"image/png":"de0cab2a893b73b54542493d937e555a3e8a336e","text/plain":"<Figure size 504x360 with 1 Axes>"},"exec_count":14,"metadata":{"image/png":{"height":289,"width":408}},"output_type":"execute_result"}},"pos":15,"type":"cell"}
{"cell_type":"code","exec_count":15,"id":"f1075f","input":"# check one test point \nrow = [-4, 4] # try one point \n# make a prediction\nyhat = classifier.predict([row])\nprint('Predicted Class: %d' % yhat)","output":{"0":{"name":"stdout","output_type":"stream","text":"Predicted Class: 0\n"}},"pos":12,"type":"cell"}
{"cell_type":"code","exec_count":16,"id":"151ed8","input":"# example of multi-class classification task\nfrom collections import Counter\nfrom numpy import where\nimport matplotlib.pyplot as plt ","pos":17,"type":"cell"}
{"cell_type":"code","exec_count":17,"id":"990d15","input":"# define dataset\nfrom sklearn.datasets import make_blobs\nX, y = make_blobs(n_samples=1000, centers=3, random_state=1)  # 1000points, 3 classes ","pos":18,"type":"cell"}
{"cell_type":"code","exec_count":18,"id":"a349d1","input":"# class label\ncounter = Counter(y)\n# plot the dataset and color the by class label\nplt.figure(1, figsize=(7, 5))\nfor label, _ in counter.items():\n\trow_ix = where(y == label)[0]\n\tplt.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\nplt.legend()\nplt.show()","output":{"0":{"data":{"image/png":"66c5fce157a040047874f29417e2d1208896dc88","text/plain":"<Figure size 504x360 with 1 Axes>"},"exec_count":18,"metadata":{"image/png":{"height":302,"width":443},"needs_background":"light"},"output_type":"execute_result"}},"pos":19,"type":"cell"}
{"cell_type":"code","exec_count":19,"id":"15753f","input":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n# # fit a logistic regression model to the data\nclassifier = LogisticRegression()\nclassifier.fit(X,y)","output":{"0":{"data":{"text/plain":"LogisticRegression()"},"exec_count":19,"output_type":"execute_result"}},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"817c37","input":"# define dataset\nfrom sklearn.datasets import make_blobs\nX, y = make_blobs(n_samples=1000, centers=2, random_state=1)  # generate 1000 points, there are 2 classes ","pos":2,"type":"cell"}
{"cell_type":"code","exec_count":20,"id":"761da7","input":"# make predictions\nexpected = y\npredicted = classifier.predict(X)","pos":21,"type":"cell"}
{"cell_type":"code","exec_count":21,"id":"0f5481","input":"# summarize the fit of the model\nprint(metrics.classification_report(expected, predicted))\nprint(metrics.confusion_matrix(expected, predicted))","output":{"0":{"name":"stdout","output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       334\n           1       0.99      1.00      1.00       333\n           2       1.00      0.99      1.00       333\n\n    accuracy                           1.00      1000\n   macro avg       1.00      1.00      1.00      1000\nweighted avg       1.00      1.00      1.00      1000\n\n[[334   0   0]\n [  0 333   0]\n [  0   2 331]]\n"}},"pos":22,"type":"cell"}
{"cell_type":"code","exec_count":22,"id":"17123b","input":"# Plot non-normalized confusion matrix\nfrom sklearn.metrics import plot_confusion_matrix\ntitles_options = [(\"Confusion matrix\", None)]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(classifier, X, y,\n                                 display_labels=y,\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title, FontSize = 20)\nplt.show()","output":{"0":{"data":{"image/png":"0adda8e1b026f1f8aeb79427bace49ed347c4ad5","text/plain":"<Figure size 864x504 with 2 Axes>"},"exec_count":22,"metadata":{"image/png":{"height":446,"width":500},"needs_background":"light"},"output_type":"execute_result"}},"pos":23,"type":"cell"}
{"cell_type":"code","exec_count":23,"id":"10555f","input":"# Plot the decision boundary. For that, we will assign a color to each\n# point in the mesh [x_min, x_max]x[y_min, y_max].\nx_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\ny_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\nh = .02  # step size in the mesh\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\nZ = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n\n# Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure(1, figsize=(7, 5))\nplt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n\n# Plot also the training points\nplt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.xticks(())\nplt.yticks(())\n\nplt.show()","output":{"0":{"data":{"image/png":"ae32ae021d40ad2e99e863db8faa4eeed1b162c0","text/plain":"<Figure size 504x360 with 1 Axes>"},"exec_count":23,"metadata":{"image/png":{"height":289,"width":408}},"output_type":"execute_result"}},"pos":24,"type":"cell"}
{"cell_type":"code","exec_count":24,"id":"680c86","input":"# example of multi-class classification task\nfrom collections import Counter\nfrom numpy import where\nfrom collections import Counter\nfrom sklearn.datasets import make_blobs\nimport matplotlib.pyplot as plt \n# define dataset\nX, y = make_blobs(n_samples=1000, centers=3, random_state=1)","pos":26,"type":"cell"}
{"cell_type":"code","exec_count":25,"id":"da598e","input":"# class label\ncounter = Counter(y)\n# plot the dataset and color the by class label\nplt.figure(1, figsize=(7, 5))\nfor label, _ in counter.items():\n\trow_ix = where(y == label)[0]\n\tplt.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\nplt.legend()\nplt.show()","output":{"0":{"data":{"image/png":"66c5fce157a040047874f29417e2d1208896dc88","text/plain":"<Figure size 504x360 with 1 Axes>"},"exec_count":25,"metadata":{"image/png":{"height":302,"width":443},"needs_background":"light"},"output_type":"execute_result"}},"pos":27,"type":"cell"}
{"cell_type":"code","exec_count":26,"id":"1dff40","input":"# Gaussian Naive Bayes\n# from sklearn import datasets\nfrom sklearn import metrics\nfrom sklearn.naive_bayes import GaussianNB\n# fit a Naive Bayes model to the data\nclassifier = GaussianNB()\nclassifier.fit(X, y)","output":{"0":{"data":{"text/plain":"GaussianNB()"},"exec_count":26,"output_type":"execute_result"}},"pos":28,"type":"cell"}
{"cell_type":"code","exec_count":27,"id":"ab8158","input":"# make predictions\nexpected = y\npredicted = classifier.predict(X)","pos":29,"type":"cell"}
{"cell_type":"code","exec_count":28,"id":"73853f","input":"# summarize the fit of the model\nprint(metrics.classification_report(expected, predicted))\nprint(metrics.confusion_matrix(expected, predicted))","output":{"0":{"name":"stdout","output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       334\n           1       0.99      1.00      1.00       333\n           2       1.00      0.99      1.00       333\n\n    accuracy                           1.00      1000\n   macro avg       1.00      1.00      1.00      1000\nweighted avg       1.00      1.00      1.00      1000\n\n[[334   0   0]\n [  0 333   0]\n [  0   2 331]]\n"}},"pos":30,"type":"cell"}
{"cell_type":"code","exec_count":29,"id":"80cf85","input":"# Plot non-normalized confusion matrix\nfrom sklearn.metrics import plot_confusion_matrix\ntitles_options = [(\"Confusion matrix\", None)]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(classifier, X, y,\n                                 display_labels=y,\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title, FontSize = 20)\nplt.show()","output":{"0":{"data":{"image/png":"0adda8e1b026f1f8aeb79427bace49ed347c4ad5","text/plain":"<Figure size 864x504 with 2 Axes>"},"exec_count":29,"metadata":{"image/png":{"height":446,"width":500},"needs_background":"light"},"output_type":"execute_result"}},"pos":31,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"322ff9","input":"type(X), type(y)","output":{"0":{"data":{"text/plain":"(numpy.ndarray, numpy.ndarray)"},"exec_count":3,"output_type":"execute_result"}},"pos":3,"type":"cell"}
{"cell_type":"code","exec_count":30,"id":"ce3a69","input":"# Plot the decision boundary. For that, we will assign a color to each\n# point in the mesh [x_min, x_max]x[y_min, y_max].\nx_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\ny_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\nh = .02  # step size in the mesh\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\nZ = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n\n# Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure(1, figsize=(7, 5))\nplt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n\n# Plot also the training points\nplt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.xticks(())\nplt.yticks(())\n\nplt.show()","output":{"0":{"data":{"image/png":"218be74adca026c85fee3e7925e173cb739824de","text/plain":"<Figure size 504x360 with 1 Axes>"},"exec_count":30,"metadata":{"image/png":{"height":289,"width":408}},"output_type":"execute_result"}},"pos":32,"type":"cell"}
{"cell_type":"code","exec_count":31,"id":"840012","input":"# example of multi-class classification task\nfrom collections import Counter\nfrom numpy import where\nfrom collections import Counter\nfrom sklearn.datasets import make_blobs\nimport matplotlib.pyplot as plt \n# define dataset\nX, y = make_blobs(n_samples=1000, centers=3, random_state=1)","pos":34,"type":"cell"}
{"cell_type":"code","exec_count":32,"id":"af2b71","input":"# example of multi-class classification task\nfrom collections import Counter\nfrom numpy import where\nfrom collections import Counter\nfrom sklearn.datasets import make_blobs\nimport matplotlib.pyplot as plt \n# define dataset\nX, y = make_blobs(n_samples=1000, centers=3, random_state=1)","pos":35,"type":"cell"}
{"cell_type":"code","exec_count":33,"id":"8d79af","input":"# class label\ncounter = Counter(y)\n# plot the dataset and color the by class label\nplt.figure(1, figsize=(7, 5))\nfor label, _ in counter.items():\n\trow_ix = where(y == label)[0]\n\tplt.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\nplt.legend()\nplt.show()","output":{"0":{"data":{"image/png":"66c5fce157a040047874f29417e2d1208896dc88","text/plain":"<Figure size 504x360 with 1 Axes>"},"exec_count":33,"metadata":{"image/png":{"height":302,"width":443},"needs_background":"light"},"output_type":"execute_result"}},"pos":36,"type":"cell"}
{"cell_type":"code","exec_count":35,"id":"da42aa","input":"# k-Nearest Neighbor\nfrom sklearn.neighbors import KNeighborsClassifier\n# fit a k-nearest neighbor model to the data\nmodel = KNeighborsClassifier()\nmodel.fit(X, y)\n# print(model)","output":{"0":{"data":{"text/plain":"KNeighborsClassifier()"},"exec_count":35,"output_type":"execute_result"}},"pos":37,"type":"cell"}
{"cell_type":"code","exec_count":36,"id":"2a97e3","input":"# make predictions\nexpected = y\npredicted = model.predict(X)","pos":38,"type":"cell"}
{"cell_type":"code","exec_count":37,"id":"4f8d55","input":"# summarize the fit of the model\nprint(metrics.classification_report(expected, predicted))\nprint(metrics.confusion_matrix(expected, predicted))","output":{"0":{"name":"stdout","output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       334\n           1       0.99      1.00      1.00       333\n           2       1.00      0.99      1.00       333\n\n    accuracy                           1.00      1000\n   macro avg       1.00      1.00      1.00      1000\nweighted avg       1.00      1.00      1.00      1000\n\n[[334   0   0]\n [  0 333   0]\n [  0   2 331]]\n"}},"pos":39,"type":"cell"}
{"cell_type":"code","exec_count":38,"id":"f6e5b8","input":"# Plot non-normalized confusion matrix\nfrom sklearn.metrics import plot_confusion_matrix\ntitles_options = [(\"Confusion matrix\", None)]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(classifier, X, y,\n                                 display_labels=y,\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title, FontSize = 20)\nplt.show()","output":{"0":{"data":{"image/png":"0adda8e1b026f1f8aeb79427bace49ed347c4ad5","text/plain":"<Figure size 864x504 with 2 Axes>"},"exec_count":38,"metadata":{"image/png":{"height":446,"width":500},"needs_background":"light"},"output_type":"execute_result"}},"pos":40,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"e9d9e9","input":"X.shape, y.shape","output":{"0":{"data":{"text/plain":"((1000, 2), (1000,))"},"exec_count":4,"output_type":"execute_result"}},"pos":4,"type":"cell"}
{"cell_type":"code","exec_count":40,"id":"91b545","input":"# Plot the decision boundary. For that, we will assign a color to each\n# point in the mesh [x_min, x_max]x[y_min, y_max].\nx_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\ny_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\nh = .02  # step size in the mesh\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\nZ = model.predict(np.c_[xx.ravel(), yy.ravel()])\n\n# Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure(1, figsize=(7, 5))\nplt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n\n# Plot also the training points\nplt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.xticks(())\nplt.yticks(())\n\nplt.show()","output":{"0":{"data":{"image/png":"631da620d1160a547ea36d87eed86f156a7b62d1","text/plain":"<Figure size 504x360 with 1 Axes>"},"exec_count":40,"metadata":{"image/png":{"height":289,"width":408}},"output_type":"execute_result"}},"pos":41,"type":"cell"}
{"cell_type":"code","exec_count":41,"id":"197147","input":"# example of multi-class classification task\nfrom collections import Counter\nfrom numpy import where\nfrom collections import Counter\nfrom sklearn.datasets import make_blobs\nimport matplotlib.pyplot as plt \n# define dataset\nX, y = make_blobs(n_samples=1000, centers=3, random_state=1)","pos":43,"type":"cell"}
{"cell_type":"code","exec_count":42,"id":"523a5d","input":"# example of multi-class classification task\nfrom collections import Counter\nfrom numpy import where\nfrom collections import Counter\nfrom sklearn.datasets import make_blobs\nimport matplotlib.pyplot as plt \n# define dataset\nX, y = make_blobs(n_samples=1000, centers=3, random_state=1)","pos":44,"type":"cell"}
{"cell_type":"code","exec_count":43,"id":"6ef7d3","input":"# class label\ncounter = Counter(y)\n# plot the dataset and color the by class label\nplt.figure(1, figsize=(7, 5))\nfor label, _ in counter.items():\n\trow_ix = where(y == label)[0]\n\tplt.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\nplt.legend()\nplt.show()","output":{"0":{"data":{"image/png":"66c5fce157a040047874f29417e2d1208896dc88","text/plain":"<Figure size 504x360 with 1 Axes>"},"exec_count":43,"metadata":{"image/png":{"height":302,"width":443},"needs_background":"light"},"output_type":"execute_result"}},"pos":45,"type":"cell"}
{"cell_type":"code","exec_count":44,"id":"00b5ae","input":"\n# from sklearn import datasets\n# from sklearn import metrics\nfrom sklearn.svm import SVC\n# fit a SVM model to the data\nmodel = SVC()\nmodel.fit(X, y)\n# print(model)\n","output":{"0":{"data":{"text/plain":"SVC()"},"exec_count":44,"output_type":"execute_result"}},"pos":46,"type":"cell"}
{"cell_type":"code","exec_count":45,"id":"836300","input":"# make predictions\nexpected = y\npredicted = model.predict(X)","pos":47,"type":"cell"}
{"cell_type":"code","exec_count":46,"id":"e99ad0","input":"# summarize the fit of the model\nprint(metrics.classification_report(expected, predicted))\nprint(metrics.confusion_matrix(expected, predicted))","output":{"0":{"name":"stdout","output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       334\n           1       0.99      1.00      1.00       333\n           2       1.00      0.99      1.00       333\n\n    accuracy                           1.00      1000\n   macro avg       1.00      1.00      1.00      1000\nweighted avg       1.00      1.00      1.00      1000\n\n[[334   0   0]\n [  0 333   0]\n [  0   2 331]]\n"}},"pos":48,"type":"cell"}
{"cell_type":"code","exec_count":47,"id":"b6df60","input":"# Plot non-normalized confusion matrix\nfrom sklearn.metrics import plot_confusion_matrix\ntitles_options = [(\"Confusion matrix\", None)]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(classifier, X, y,\n                                 display_labels=y,\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title, FontSize = 20)\nplt.show()","output":{"0":{"data":{"image/png":"0adda8e1b026f1f8aeb79427bace49ed347c4ad5","text/plain":"<Figure size 864x504 with 2 Axes>"},"exec_count":47,"metadata":{"image/png":{"height":446,"width":500},"needs_background":"light"},"output_type":"execute_result"}},"pos":49,"type":"cell"}
{"cell_type":"code","exec_count":48,"id":"7e0cc0","input":"# Plot the decision boundary. For that, we will assign a color to each\n# point in the mesh [x_min, x_max]x[y_min, y_max].\nx_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\ny_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\nh = .02  # step size in the mesh\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\nZ = model.predict(np.c_[xx.ravel(), yy.ravel()])\n\n# Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure(1, figsize=(7, 5))\nplt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n\n# Plot also the training points\nplt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.xticks(())\nplt.yticks(())\n\nplt.show()","output":{"0":{"data":{"image/png":"958cfe84f73444a45901eeb26ed9a44d9263a16f","text/plain":"<Figure size 504x360 with 1 Axes>"},"exec_count":48,"metadata":{"image/png":{"height":289,"width":408}},"output_type":"execute_result"}},"pos":50,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"07d652","input":"# check class label\nfrom collections import Counter\ncounter = Counter(y)\nprint(counter)","output":{"0":{"name":"stdout","output_type":"stream","text":"Counter({0: 500, 1: 500})\n"}},"pos":5,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"b111aa","input":"X[:4]","output":{"0":{"data":{"text/plain":"array([[-3.05837272,  4.48825769],\n       [-8.60973869, -3.72714879],\n       [ 1.37129721,  5.23107449],\n       [-9.33917563, -2.9544469 ]])"},"exec_count":6,"output_type":"execute_result"}},"pos":6,"type":"cell"}
{"cell_type":"code","exec_count":7,"id":"f1fcea","input":"y[:4]","output":{"0":{"data":{"text/plain":"array([0, 1, 0, 1])"},"exec_count":7,"output_type":"execute_result"}},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"467080","input":"# show first few examples\nfor i in range(5):\n    print(X[i], y[i])","output":{"0":{"name":"stdout","output_type":"stream","text":"[-3.05837272  4.48825769] 0\n[-8.60973869 -3.72714879] 1\n[1.37129721 5.23107449] 0\n[-9.33917563 -2.9544469 ] 1\n[-11.57178593  -3.85275513] 1\n"}},"pos":8,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"2c7529","input":"# plot the dataset and color the by class label\n# example of binary classification task\nfrom numpy import where\nplt.figure(1, figsize=(7, 5))\nfor label, _ in counter.items():\n    row_ix = where(y == label)[0]\n    plt.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\nplt.legend()\nplt.show()","output":{"0":{"data":{"image/png":"2e085d35387da80efd9535dc905acb846ca6dfb8","text/plain":"<Figure size 504x360 with 1 Axes>"},"exec_count":9,"metadata":{"image/png":{"height":302,"width":426},"needs_background":"light"},"output_type":"execute_result"}},"pos":9,"type":"cell"}
{"cell_type":"markdown","id":"12053e","input":"### Naive Bayes","pos":25,"type":"cell"}
{"cell_type":"markdown","id":"6c34f6","input":"### perceptron algorithm ","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"94486d","input":"### Logistic Regression","pos":16,"type":"cell"}
{"cell_type":"markdown","id":"b946b4","input":"### k-Nearest Neighbor","pos":33,"type":"cell"}
{"cell_type":"markdown","id":"bbc854","input":"### Support Vector Machine","pos":42,"type":"cell"}
{"cell_type":"markdown","id":"bcde7f","input":"### Random forest/decision tree \n\n\n\nhttps://scikit-learn.org/stable/modules/tree.html#classification","pos":51,"type":"cell"}
{"id":0,"time":1627544904883,"type":"user"}
{"last_load":1627544905169,"type":"file"}