{"backend_state":"running","connection_file":"/projects/ae15c660-30de-474e-abca-5963358c9eb9/.local/share/jupyter/runtime/kernel-ca2dfd27-b52b-4df4-a0cd-e6384ec92d0c.json","kernel":"python3-ubuntu","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1627541849708,"exec_count":1,"id":"2ae20f","input":"# import libraries \nimport numpy as np \nimport matplotlib.pyplot as plt","kernel":"python3-ubuntu","pos":1,"start":1627541849703,"state":"done","type":"cell"}
{"cell_type":"code","end":1627541850423,"exec_count":2,"id":"12ea77","input":"# initialize your random seed to ensure reproducibility of your result\nnp.random.seed(42) # (The Story of Seed(42)) https://medium.com/@leticia.b/the-story-of-seed-42-874953452b94\n\n# randomly generate x which is avector of 100 points \nx = np.random.rand(100, 1)\n\n# define exact linear function y = 1 + 2x + epsilon where epsilon (0.1*random numbers)\n# 1 = y-intercept \n# 2 = slope \ny = 1 + 2 * x + .1 * np.random.randn(100, 1)","kernel":"python3-ubuntu","pos":3,"start":1627541850419,"state":"done","type":"cell"}
{"cell_type":"code","end":1627541850778,"exec_count":3,"id":"367d1f","input":"print(len(x))","kernel":"python3-ubuntu","output":{"0":{"name":"stdout","text":"100\n"}},"pos":4,"start":1627541850772,"state":"done","type":"cell"}
{"cell_type":"code","end":1627541851331,"exec_count":4,"id":"7f6ff4","input":"plt.figure(figsize=(10,5))\n\n# plot the entire data set \nplt.scatter(x,y, c='blue')  \nplt.xlabel('x', fontsize = 20) \nplt.ylabel('y', fontsize = 20)\nplt.title('entire dataset, function y = 1 + 2x + epsilon, a = 1, b = 2')\nplt.grid('on')","kernel":"python3-ubuntu","output":{"0":{"data":{"image/png":"bff62930748fcc95a9ec4eec7fecb27d7e5294a7","text/plain":"<Figure size 720x360 with 1 Axes>"},"metadata":{"image/png":{"height":342,"width":619},"needs_background":"light"}}},"pos":5,"start":1627541850987,"state":"done","type":"cell"}
{"cell_type":"code","end":1627541851340,"exec_count":5,"id":"580485","input":"idx = np.arange(100)\nprint(idx)","kernel":"python3-ubuntu","output":{"0":{"name":"stdout","text":"[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n 96 97 98 99]\n"}},"pos":7,"start":1627541851337,"state":"done","type":"cell"}
{"cell_type":"code","end":1627541851410,"exec_count":6,"id":"7d7c78","input":"# Shuffles the indices\nidx = np.arange(100)\nnp.random.shuffle(idx)\nprint(idx)","kernel":"python3-ubuntu","output":{"0":{"name":"stdout","text":"[76 83 80 98  2 77 71 84 89 50 40 51 67 86 37 49  4 10 69 81  9 54 55 87\n 64 44 90 75 33 30 93 95 14 61 11 13 15  7  0 19 35  6 12 65 70 88 56 58\n 28 38 91 42  8 73 39 85 25 92 41 26  1 22 21 46 74 79 78 72 57 53 24 17\n 66 32 31 62 59 52 82 23 36  5 45 99 43 16 48 94 34  3 18 47 60 68 63 27\n 96 29 20 97]\n"}},"pos":8,"start":1627541851402,"state":"done","type":"cell"}
{"cell_type":"code","end":1627541851607,"exec_count":7,"id":"d47cf4","input":"# Uses first 80 random indices for train\ntrain_idx = idx[:80]\n\n# Uses the remaining indices for validation\nval_idx = idx[80:]\n\n# Generates train and validation sets\nx_train, y_train = x[train_idx], y[train_idx]\nx_val, y_val = x[val_idx], y[val_idx]\n","kernel":"python3-ubuntu","pos":9,"start":1627541851603,"state":"done","type":"cell"}
{"cell_type":"code","end":1627541851808,"exec_count":8,"id":"00e083","input":"print(len(x_train))\nprint(len(y_train))","kernel":"python3-ubuntu","output":{"0":{"name":"stdout","text":"80\n80\n"}},"pos":10,"start":1627541851802,"state":"done","type":"cell"}
{"cell_type":"code","end":1627541852000,"exec_count":9,"id":"adebe4","input":"print(len(x_val))\nprint(len(y_val))","kernel":"python3-ubuntu","output":{"0":{"name":"stdout","text":"20\n20\n"}},"pos":11,"start":1627541851995,"state":"done","type":"cell"}
{"cell_type":"code","end":1627541852714,"exec_count":10,"id":"e077b7","input":"plt.figure(figsize=(10,5))\n\n# plot the train set \nplt.subplot(1,2,1)\nplt.scatter(x_train,y_train, c='orange')  \nplt.xlabel('x', fontsize = 20) \nplt.ylabel('y', fontsize = 20)\nplt.title('Train Data')\nplt.grid('on')\n\n# plot the validation set \nplt.subplot(1,2,2)\nplt.scatter(x_val,x_val)  \nplt.xlabel('x', fontsize = 20) \nplt.ylabel('y', fontsize = 20)\nplt.title('Validation Data')\nplt.grid('on')\n\nplt.show()","kernel":"python3-ubuntu","output":{"0":{"data":{"image/png":"2adb379a86b2332a56b5fac154a3435185a4e326","text/plain":"<Figure size 720x360 with 2 Axes>"},"metadata":{"image/png":{"height":342,"width":621},"needs_background":"light"}}},"pos":13,"start":1627541852334,"state":"done","type":"cell"}
{"cell_type":"code","end":1627541852724,"exec_count":11,"id":"ad6f88","input":"# initialize your random seed to ensure reproducibility of your result\nnp.random.seed(42)\n\n# Initializes parameters \"a\" and \"b\" randomly \na = np.random.randn(1)\nb = np.random.randn(1)\n\n# print values of a and b \nprint(a, b)\n","kernel":"python3-ubuntu","output":{"0":{"name":"stdout","text":"[0.49671415] [-0.1382643]\n"}},"pos":15,"start":1627541852720,"state":"done","type":"cell"}
{"cell_type":"code","end":1627541852889,"exec_count":12,"id":"b20388","input":"# Initialization of hyper-parameters (in our case, only learning rate and number of epochs)\n\n# Sets learning rate\nlr = 1e-1\n# Defines number of epochs|\nn_epochs = 1000","kernel":"python3-ubuntu","pos":16,"start":1627541852885,"state":"done","type":"cell"}
{"cell_type":"code","end":1627541855094,"exec_count":13,"id":"1edbde","input":"for epoch in range(n_epochs):\n    # Computes our model's predicted output\n    yhat = a + b * x_train\n    \n    # How wrong is our model? That's the error! \n    error = (y_train - yhat)\n    \n    # It is a regression, so it computes mean squared error (MSE)\n    loss = (error ** 2).mean()\n    \n    # Computes gradients for both \"a\" and \"b\" parameters\n    a_grad = -2 * error.mean()\n    b_grad = -2 * (x_train * error).mean()\n    \n    # Updates parameters using gradients and the learning rate\n    a = a - lr * a_grad  # new parameter a = old parameter a - learning rate * gradient of a\n    b = b - lr * b_grad\n    \nprint(a, b)","kernel":"python3-ubuntu","output":{"0":{"name":"stdout","text":"[1.02354094] [1.96896411]\n"}},"pos":18,"start":1627541855068,"state":"done","type":"cell"}
{"cell_type":"code","end":1627541857080,"exec_count":14,"id":"020f06","input":"from sklearn.linear_model import LinearRegression\nlinr = LinearRegression()\nlinr.fit(x_train, y_train)\nprint(linr.intercept_, linr.coef_[0])","kernel":"python3-ubuntu","output":{"0":{"name":"stdout","text":"[1.02354075] [1.96896447]\n"}},"pos":20,"start":1627541856658,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"931c68","input":"","pos":56,"type":"cell"}
{"cell_type":"markdown","id":"12d513","input":"## check our results use Scikit-learn's linear regression\n\nJust to make sure we haven’t done any mistakes in our code, we can use Scikit-Learn’s Linear Regression to fit the model and compare the coefficients.\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html","pos":19,"type":"cell"}
{"cell_type":"markdown","id":"390dfa","input":"## linear regression using NumPy ","pos":14,"type":"cell"}
{"cell_type":"markdown","id":"612036","input":"## The results!\n\nThey match up to 6 decimal places — we have a fully working implementation of linear regression using NumPy.","pos":21,"type":"cell"}
{"cell_type":"markdown","id":"616796","input":"# Linear regression using NumPy","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"619471","input":"### For each epoch, there are 5 training steps:\n* Compute model’s predictions \n* Compute the error (the difference between the actual value and predicted value) \n* Compute the loss ( mean square error = the average of (error)^2)\n* Compute the gradients for every parameter (require calculus)\n* Update the parameters a and b","pos":17,"type":"cell"}
{"cell_type":"markdown","id":"a9eed7","input":"## split data into train and validation sets (80/20)\n\nyou give 80% of the data points to the computer to learn and predict the line equation y = b0 + b1*x\n\nyou will use 20% of the dataset to test how good the algorithm is.","pos":6,"type":"cell"}
{"cell_type":"markdown","id":"ba6db5","input":"## Data Generation","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"e2e72e","input":"## plot the train and validation sets","pos":12,"type":"cell"}
{"id":0,"time":1627541839644,"type":"user"}
{"last_load":1627541839849,"type":"file"}